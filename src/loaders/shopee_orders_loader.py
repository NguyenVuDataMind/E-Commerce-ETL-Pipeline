#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
Shopee Orders Data Loader
T√≠ch h·ª£p v·ªõi Facolos Enterprise ETL Infrastructure
"""

import pandas as pd
from sqlalchemy import create_engine, text
from datetime import datetime
from typing import Dict, List, Any, Optional
import logging
import sys
import os

# Import shared utilities
sys.path.append(os.path.dirname(os.path.dirname(os.path.dirname(os.path.abspath(__file__)))))
from config.settings import settings
from src.utils.logging import setup_logging

logger = setup_logging(__name__)

class ShopeeOrderLoader:
    """
    Shopee Orders Data Loader - T∆∞∆°ng t·ª± TikTok Shop v√† MISA CRM pattern
    """
    
    def __init__(self):
        """Kh·ªüi t·∫°o Shopee Order Loader"""
        self.db_engine = create_engine(settings.sql_server_connection_string)
        
        # Table mappings - s·ª≠ d·ª•ng staging schema, b·∫£ng Shopee c√≥ ti·ªÅn t·ªë shopee_
        self.table_mappings = {
            'orders': settings.get_table_full_name('shopee', 'shopee_orders'),
            'recipient_address': settings.get_table_full_name('shopee', 'shopee_recipient_address'),
            'order_items': settings.get_table_full_name('shopee', 'shopee_order_items'),
            'order_item_locations': settings.get_table_full_name('shopee', 'shopee_order_item_locations'),
            'packages': settings.get_table_full_name('shopee', 'shopee_packages'),
            'package_items': settings.get_table_full_name('shopee', 'shopee_package_items'),
            'invoice': settings.get_table_full_name('shopee', 'shopee_invoice'),
            'payment_info': settings.get_table_full_name('shopee', 'shopee_payment_info'),
            'order_pending_terms': settings.get_table_full_name('shopee', 'shopee_order_pending_terms'),
            'order_warnings': settings.get_table_full_name('shopee', 'shopee_order_warnings'),
            'prescription_images': settings.get_table_full_name('shopee', 'shopee_prescription_images'),
            'buyer_proof_of_collection': settings.get_table_full_name('shopee', 'shopee_buyer_proof_of_collection')
        }
        
        logger.info(f"Kh·ªüi t·∫°o Shopee Order Loader cho {settings.company_name}")
        logger.info(f"Database: {settings.sql_server_host}")
        logger.info(f"Schema: {settings.schema_mappings.get('shopee', 'staging')}")
    
    def _get_table_info(self, table_full_name: str) -> Dict[str, Any]:
        """
        L·∫•y th√¥ng tin v·ªÅ table (schema, table name)
        
        Args:
            table_full_name: T√™n ƒë·∫ßy ƒë·ªß c·ªßa table (schema.table)
            
        Returns:
            Dict ch·ª©a schema v√† table name
        """
        parts = table_full_name.split('.')
        if len(parts) == 2:
            return {'schema': parts[0], 'table': parts[1]}
        else:
            return {'schema': 'staging', 'table': table_full_name}
    
    def _convert_datetime_to_naive(self, df: pd.DataFrame) -> pd.DataFrame:
        """Chuy·ªÉn ƒë·ªïi datetime columns t·ª´ timezone-aware sang timezone-naive"""
        df_copy = df.copy()
        
        for col in df_copy.columns:
            if df_copy[col].dtype == 'datetime64[ns, UTC]':
                df_copy[col] = df_copy[col].dt.tz_localize(None)
            elif 'datetime' in str(df_copy[col].dtype):
                df_copy[col] = pd.to_datetime(df_copy[col], utc=True).dt.tz_localize(None)
        
        return df_copy
    
    def truncate_table(self, table_name: str) -> bool:
        """
        X√≥a t·∫•t c·∫£ d·ªØ li·ªáu trong table (Full Load) theo chu·∫©n SQL Server
        
        Args:
            table_name: T√™n table c·∫ßn truncate
            
        Returns:
            True n·∫øu th√†nh c√¥ng, False n·∫øu th·∫•t b·∫°i
        """
        table_full_name = self.table_mappings.get(table_name)
        if not table_full_name:
            logger.error(f"‚ùå Table mapping not found for: {table_name}")
            return False
        
        try:
            with self.db_engine.connect() as conn:
                schema, table = table_full_name.split('.')

                # V·ªõi SQL Server, TRUNCATE TABLE kh√¥ng th·ªÉ d√πng khi c√≥ FK tham chi·∫øu.
                # V√¨ b·∫£ng orders ƒë∆∞·ª£c tham chi·∫øu b·ªüi nhi·ªÅu b·∫£ng con, thay th·∫ø b·∫±ng DELETE theo th·ª© t·ª± an to√†n.
                if table_name == 'orders':
                    logger.info("‚Ü©Ô∏è Detected parent table 'orders' ‚Äî performing safe cascade DELETE on child tables first")
                    self._delete_shopee_children_tables(conn, schema)

                # Th·ª±c hi·ªán DELETE thay cho TRUNCATE ƒë·ªÉ kh√¥ng v∆∞·ªõng FK
                delete_sql = f"DELETE FROM {table_full_name}"
                result = conn.execute(text(delete_sql))
                conn.commit()

                logger.info(f"‚úÖ Cleared table via DELETE: {table_full_name} (rows affected: {result.rowcount})")
                return True
                
        except Exception as e:
            logger.error(f"‚ùå Failed to truncate table {table_full_name}: {str(e)}")
            return False

    def _delete_shopee_children_tables(self, conn, schema: str) -> None:
        """X√≥a d·ªØ li·ªáu c√°c b·∫£ng con c·ªßa Shopee theo ƒë√∫ng th·ª© t·ª± ƒë·ªÉ ƒë·∫£m b·∫£o r√†ng bu·ªôc FK.

        Th·ª© t·ª± x√≥a (child -> parent):
          - package_items (tham chi·∫øu packages, order_items)
          - order_item_locations (tham chi·∫øu order_items)
          - packages (tham chi·∫øu orders)
          - invoice (tham chi·∫øu orders)
          - payment_info (tham chi·∫øu orders)
          - order_pending_terms (tham chi·∫øu orders)
          - order_warnings (tham chi·∫øu orders)
          - prescription_images (tham chi·∫øu orders)
          - buyer_proof_of_collection (tham chi·∫øu orders)
          - order_items (tham chi·∫øu orders)
          - recipient_address (tham chi·∫øu orders)
        """
        tables_in_order = [
            'shopee_package_items',
            'shopee_order_item_locations',
            'shopee_packages',
            'shopee_invoice',
            'shopee_payment_info',
            'shopee_order_pending_terms',
            'shopee_order_warnings',
            'shopee_prescription_images',
            'shopee_buyer_proof_of_collection',
            'shopee_order_items',
            'shopee_recipient_address',
        ]

        for tbl in tables_in_order:
            full_name = f"{schema}.{tbl}"
            try:
                res = conn.execute(text(f"IF OBJECT_ID('{full_name}', 'U') IS NOT NULL DELETE FROM {full_name}"))
                # M·ªôt s·ªë driver kh√¥ng tr·∫£ rowcount cho c√¢u IF... n√™n c·∫ßn try/except ri√™ng
                affected = getattr(res, 'rowcount', None)
                logger.info(f"   üóëÔ∏è Cleared child table: {full_name}{'' if affected is None else f' (rows: {affected})'}")
            except Exception as e:
                logger.warning(f"   ‚ö†Ô∏è Skipped deleting {full_name}: {e}")
    
    def load_dataframe_to_table(self, df: pd.DataFrame, table_name: str, 
                               if_exists: str = 'append') -> bool:
        """
        Load DataFrame v√†o table
        
        Args:
            df: DataFrame c·∫ßn load
            table_name: T√™n table ƒë√≠ch
            if_exists: X·ª≠ l√Ω khi table ƒë√£ t·ªìn t·∫°i ('append', 'replace', 'fail')
            
        Returns:
            True n·∫øu th√†nh c√¥ng, False n·∫øu th·∫•t b·∫°i
        """
        if df.empty:
            logger.warning(f"‚ö†Ô∏è DataFrame for {table_name} is empty, skipping")
            return True
        
        table_full_name = self.table_mappings.get(table_name)
        if not table_full_name:
            logger.error(f"‚ùå Table mapping not found for: {table_name}")
            return False
        
        try:
            # Convert datetime columns to timezone-naive
            df_export = self._convert_datetime_to_naive(df)
            
            # Load to database
            df_export.to_sql(
                name=table_full_name.split('.')[1],  # Table name only
                con=self.db_engine,
                schema=table_full_name.split('.')[0],  # Schema name
                if_exists=if_exists,
                index=False,
                method='multi',
                chunksize=1000
            )
            
            logger.info(f"‚úÖ Loaded {len(df)} rows to {table_full_name}")
            return True
            
        except Exception as e:
            logger.error(f"‚ùå Failed to load DataFrame to {table_full_name}: {str(e)}")
            return False
    
    def load_orders_full_load(self, dataframes: Dict[str, pd.DataFrame]) -> bool:
        """
        Load d·ªØ li·ªáu full load cho t·∫•t c·∫£ c√°c b·∫£ng Shopee
        
        Args:
            dataframes: Dictionary ch·ª©a c√°c DataFrame theo ERD
            
        Returns:
            True n·∫øu th√†nh c√¥ng, False n·∫øu th·∫•t b·∫°i
        """
        logger.info("üöÄ Starting Shopee full load data loading...")
        
        try:
            # Load theo th·ª© t·ª± ƒë·ªÉ tr√°nh foreign key constraint
            load_order = [
                'orders',  # Main table first
                'recipient_address',
                'order_items',
                'order_item_locations',
                'packages',
                'package_items',
                'invoice',
                'payment_info',
                'order_pending_terms',
                'order_warnings',
                'prescription_images',
                'buyer_proof_of_collection'
            ]
            
            success_count = 0
            total_count = len(load_order)
            
            for table_name in load_order:
                if table_name in dataframes:
                    df = dataframes[table_name]
                    
                    if not df.empty:
                        # Truncate table tr∆∞·ªõc khi load (full load)
                        if self.truncate_table(table_name):
                            if self.load_dataframe_to_table(df, table_name, 'append'):
                                success_count += 1
                                logger.info(f"‚úÖ Successfully loaded {table_name}: {len(df)} rows")
                            else:
                                logger.error(f"‚ùå Failed to load {table_name}")
                        else:
                            logger.error(f"‚ùå Failed to truncate {table_name}")
                    else:
                        logger.info(f"üì≠ Skipping empty {table_name}")
                        success_count += 1  # Empty table is considered success
            
            if success_count == total_count:
                logger.info(f"üéâ Full load completed successfully: {success_count}/{total_count} tables")
                return True
            else:
                logger.error(f"‚ùå Full load failed: {success_count}/{total_count} tables")
                return False
                
        except Exception as e:
            logger.error(f"‚ùå Full load failed with exception: {str(e)}")
            return False
    
    def load_orders_incremental(self, df: pd.DataFrame) -> bool:
        """
        Load d·ªØ li·ªáu incremental cho Shopee orders (UPSERT logic)
        
        Args:
            df: DataFrame ch·ª©a orders m·ªõi
            
        Returns:
            True n·∫øu th√†nh c√¥ng, False n·∫øu th·∫•t b·∫°i
        """
        logger.info("üîÑ Starting Shopee incremental data loading...")
        
        if df.empty:
            logger.info("üì≠ No incremental data to load")
            return True
        
        try:
            # Convert datetime columns to timezone-naive
            df_export = self._convert_datetime_to_naive(df)
            
            # Load to main orders table with UPSERT logic
            table_full_name = self.table_mappings['orders']
            
            # Use pandas to_sql with if_exists='append' for now
            # In production, implement proper UPSERT with SQL MERGE statement
            df_export.to_sql(
                name=table_full_name.split('.')[1],
                con=self.db_engine,
                schema=table_full_name.split('.')[0],
                if_exists='append',
                index=False,
                method='multi',
                chunksize=1000
            )
            
            logger.info(f"‚úÖ Loaded {len(df)} incremental orders to {table_full_name}")
            return True
            
        except Exception as e:
            logger.error(f"‚ùå Incremental load failed: {str(e)}")
            return False
    
    def load_flat_orders_dataframe(self, df: pd.DataFrame, load_type: str = 'full') -> bool:
        """
        Load DataFrame ph·∫≥ng v√†o b·∫£ng orders ch√≠nh (t∆∞∆°ng th√≠ch v·ªõi TikTok Shop pattern)
        
        Args:
            df: DataFrame ph·∫≥ng ch·ª©a orders
            load_type: 'full' ho·∫∑c 'incremental'
            
        Returns:
            True n·∫øu th√†nh c√¥ng, False n·∫øu th·∫•t b·∫°i
        """
        if df.empty:
            logger.info("üì≠ No data to load")
            return True
        
        try:
            # Convert datetime columns to timezone-naive
            df_export = self._convert_datetime_to_naive(df)
            
            table_full_name = self.table_mappings['orders']
            
            if load_type == 'full':
                # Truncate table tr∆∞·ªõc khi load
                if not self.truncate_table('orders'):
                    return False
                
                if_exists = 'append'
            else:
                if_exists = 'append'  # Incremental: append new data
            
            # Load to database
            df_export.to_sql(
                name=table_full_name.split('.')[1],
                con=self.db_engine,
                schema=table_full_name.split('.')[0],
                if_exists=if_exists,
                index=False,
                method='multi',
                chunksize=1000
            )
            
            logger.info(f"‚úÖ Loaded {len(df)} orders ({load_type} load) to {table_full_name}")
            return True
            
        except Exception as e:
            logger.error(f"‚ùå Failed to load orders DataFrame: {str(e)}")
            return False
    
    def get_table_row_count(self, table_name: str) -> int:
        """
        L·∫•y s·ªë d√≤ng trong table
        
        Args:
            table_name: T√™n table
            
        Returns:
            S·ªë d√≤ng trong table
        """
        table_full_name = self.table_mappings.get(table_name)
        if not table_full_name:
            return 0
        
        try:
            with self.db_engine.connect() as conn:
                result = conn.execute(text(f"SELECT COUNT(*) FROM {table_full_name}"))
                count = result.scalar()
                return count
        except Exception as e:
            logger.error(f"‚ùå Failed to get row count for {table_full_name}: {str(e)}")
            return 0
    
    def validate_data_integrity(self) -> Dict[str, Any]:
        """
        Ki·ªÉm tra t√≠nh to√†n v·∫πn d·ªØ li·ªáu sau khi load
        
        Returns:
            Dictionary ch·ª©a k·∫øt qu·∫£ validation
        """
        logger.info("üîç Validating data integrity...")
        
        validation_results = {}
        
        for table_name, table_full_name in self.table_mappings.items():
            try:
                row_count = self.get_table_row_count(table_name)
                validation_results[table_name] = {
                    'row_count': row_count,
                    'status': 'success' if row_count >= 0 else 'error'
                }
            except Exception as e:
                validation_results[table_name] = {
                    'row_count': 0,
                    'status': 'error',
                    'error': str(e)
                }
        
        # Log validation results
        for table_name, result in validation_results.items():
            if result['status'] == 'success':
                logger.info(f"‚úÖ {table_name}: {result['row_count']} rows")
            else:
                logger.error(f"‚ùå {table_name}: {result.get('error', 'Unknown error')}")
        
        return validation_results
