#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
Shopee Orders Data Loader
T√≠ch h·ª£p v·ªõi Facolos Enterprise ETL Infrastructure
"""

import pandas as pd
from sqlalchemy import create_engine, text
from datetime import datetime
from typing import Dict, List, Any, Optional
import logging
import sys
import os

# Import shared utilities
sys.path.append(
    os.path.dirname(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))
)
from config.settings import settings
from src.utils.logging import setup_logging

logger = setup_logging(__name__)


class ShopeeOrderLoader:
    """
    Shopee Orders Data Loader - T∆∞∆°ng t·ª± TikTok Shop v√† MISA CRM pattern
    """

    def __init__(self):
        """Kh·ªüi t·∫°o Shopee Order Loader"""
        self.db_engine = create_engine(settings.sql_server_connection_string)

        # Table mappings - s·ª≠ d·ª•ng staging schema, b·∫£ng Shopee c√≥ ti·ªÅn t·ªë shopee_
        self.table_mappings = {
            "orders": settings.get_table_full_name("shopee", "shopee_orders"),
            "recipient_address": settings.get_table_full_name(
                "shopee", "shopee_recipient_address"
            ),
            "order_items": settings.get_table_full_name("shopee", "shopee_order_items"),
            "order_item_locations": settings.get_table_full_name(
                "shopee", "shopee_order_item_locations"
            ),
            "packages": settings.get_table_full_name("shopee", "shopee_packages"),
            "package_items": settings.get_table_full_name(
                "shopee", "shopee_package_items"
            ),
            "invoice": settings.get_table_full_name("shopee", "shopee_invoice"),
            "payment_info": settings.get_table_full_name(
                "shopee", "shopee_payment_info"
            ),
            "order_pending_terms": settings.get_table_full_name(
                "shopee", "shopee_order_pending_terms"
            ),
            "order_warnings": settings.get_table_full_name(
                "shopee", "shopee_order_warnings"
            ),
            "prescription_images": settings.get_table_full_name(
                "shopee", "shopee_prescription_images"
            ),
            "buyer_proof_of_collection": settings.get_table_full_name(
                "shopee", "shopee_buyer_proof_of_collection"
            ),
        }

        logger.info(f"Kh·ªüi t·∫°o Shopee Order Loader cho {settings.company_name}")
        logger.info(f"Database: {settings.sql_server_host}")
        logger.info(f"Schema: {settings.schema_mappings.get('shopee', 'staging')}")

    def _get_table_info(self, table_full_name: str) -> Dict[str, Any]:
        """
        L·∫•y th√¥ng tin v·ªÅ table (schema, table name)

        Args:
            table_full_name: T√™n ƒë·∫ßy ƒë·ªß c·ªßa table (schema.table)

        Returns:
            Dict ch·ª©a schema v√† table name
        """
        parts = table_full_name.split(".")
        if len(parts) == 2:
            return {"schema": parts[0], "table": parts[1]}
        else:
            return {"schema": "staging", "table": table_full_name}

    def _convert_datetime_to_naive(self, df: pd.DataFrame) -> pd.DataFrame:
        """Chuy·ªÉn ƒë·ªïi datetime columns t·ª´ timezone-aware sang timezone-naive"""
        df_copy = df.copy()

        for col in df_copy.columns:
            if df_copy[col].dtype == "datetime64[ns, UTC]":
                df_copy[col] = df_copy[col].dt.tz_localize(None)
            elif "datetime" in str(df_copy[col].dtype):
                df_copy[col] = pd.to_datetime(df_copy[col], utc=True).dt.tz_localize(
                    None
                )

        return df_copy

    def truncate_table(self, table_name: str) -> bool:
        """
        X√≥a t·∫•t c·∫£ d·ªØ li·ªáu trong table (Full Load) theo chu·∫©n SQL Server

        Args:
            table_name: T√™n table c·∫ßn truncate

        Returns:
            True n·∫øu th√†nh c√¥ng, False n·∫øu th·∫•t b·∫°i
        """
        table_full_name = self.table_mappings.get(table_name)
        if not table_full_name:
            logger.error(f"‚ùå Table mapping not found for: {table_name}")
            return False

        try:
            with self.db_engine.connect() as conn:
                schema, table = table_full_name.split(".")

                # V·ªõi SQL Server, TRUNCATE TABLE kh√¥ng th·ªÉ d√πng khi c√≥ FK tham chi·∫øu.
                # V√¨ b·∫£ng orders ƒë∆∞·ª£c tham chi·∫øu b·ªüi nhi·ªÅu b·∫£ng con, thay th·∫ø b·∫±ng DELETE theo th·ª© t·ª± an to√†n.
                if table_name == "orders":
                    logger.info(
                        "‚Ü©Ô∏è Detected parent table 'orders' ‚Äî performing safe cascade DELETE on child tables first"
                    )
                    self._delete_shopee_children_tables(conn, schema)

                # Th·ª±c hi·ªán DELETE thay cho TRUNCATE ƒë·ªÉ kh√¥ng v∆∞·ªõng FK
                delete_sql = f"DELETE FROM {table_full_name}"
                result = conn.execute(text(delete_sql))
                conn.commit()

                logger.info(
                    f"‚úÖ Cleared table via DELETE: {table_full_name} (rows affected: {result.rowcount})"
                )
                return True

        except Exception as e:
            logger.error(f"‚ùå Failed to truncate table {table_full_name}: {str(e)}")
            return False

    def _delete_shopee_children_tables(self, conn, schema: str) -> None:
        """X√≥a d·ªØ li·ªáu c√°c b·∫£ng con c·ªßa Shopee theo ƒë√∫ng th·ª© t·ª± ƒë·ªÉ ƒë·∫£m b·∫£o r√†ng bu·ªôc FK.

        Th·ª© t·ª± x√≥a (child -> parent):
          - package_items (tham chi·∫øu packages, order_items)
          - order_item_locations (tham chi·∫øu order_items)
          - packages (tham chi·∫øu orders)
          - invoice (tham chi·∫øu orders)
          - payment_info (tham chi·∫øu orders)
          - order_pending_terms (tham chi·∫øu orders)
          - order_warnings (tham chi·∫øu orders)
          - prescription_images (tham chi·∫øu orders)
          - buyer_proof_of_collection (tham chi·∫øu orders)
          - order_items (tham chi·∫øu orders)
          - recipient_address (tham chi·∫øu orders)
        """
        tables_in_order = [
            "shopee_package_items",
            "shopee_order_item_locations",
            "shopee_packages",
            "shopee_invoice",
            "shopee_payment_info",
            "shopee_order_pending_terms",
            "shopee_order_warnings",
            "shopee_prescription_images",
            "shopee_buyer_proof_of_collection",
            "shopee_order_items",
            "shopee_recipient_address",
        ]

        for tbl in tables_in_order:
            full_name = f"{schema}.{tbl}"
            try:
                res = conn.execute(
                    text(
                        f"IF OBJECT_ID('{full_name}', 'U') IS NOT NULL DELETE FROM {full_name}"
                    )
                )
                # M·ªôt s·ªë driver kh√¥ng tr·∫£ rowcount cho c√¢u IF... n√™n c·∫ßn try/except ri√™ng
                affected = getattr(res, "rowcount", None)
                logger.info(
                    f"   üóëÔ∏è Cleared child table: {full_name}{'' if affected is None else f' (rows: {affected})'}"
                )
            except Exception as e:
                logger.warning(f"   ‚ö†Ô∏è Skipped deleting {full_name}: {e}")

    def load_dataframe_to_table(
        self, df: pd.DataFrame, table_name: str, if_exists: str = "append"
    ) -> bool:
        """
        Load DataFrame v√†o table

        Args:
            df: DataFrame c·∫ßn load
            table_name: T√™n table ƒë√≠ch
            if_exists: X·ª≠ l√Ω khi table ƒë√£ t·ªìn t·∫°i ('append', 'replace', 'fail')

        Returns:
            True n·∫øu th√†nh c√¥ng, False n·∫øu th·∫•t b·∫°i
        """
        if df.empty:
            logger.warning(f"‚ö†Ô∏è DataFrame for {table_name} is empty, skipping")
            return True

        table_full_name = self.table_mappings.get(table_name)
        if not table_full_name:
            logger.error(f"‚ùå Table mapping not found for: {table_name}")
            return False

        try:
            # Convert datetime columns to timezone-naive
            df_export = self._convert_datetime_to_naive(df)

            # Load to database (gi·ªõi h·∫°n chunksize nh·ªè ƒë·ªÉ tr√°nh qu√° t·∫£i tham s·ªë ODBC/SQL Server)
            df_export.to_sql(
                name=table_full_name.split(".")[1],  # Table name only
                con=self.db_engine,
                schema=table_full_name.split(".")[0],  # Schema name
                if_exists=if_exists,
                index=False,
                method="multi",
                chunksize=15,
            )

            logger.info(f"‚úÖ Loaded {len(df)} rows to {table_full_name}")
            return True

        except Exception as e:
            logger.error(f"‚ùå Failed to load DataFrame to {table_full_name}: {str(e)}")
            return False

    def load_orders_full_load(self, dataframes: Dict[str, pd.DataFrame]) -> bool:
        """
        Load d·ªØ li·ªáu full load cho t·∫•t c·∫£ c√°c b·∫£ng Shopee

        Args:
            dataframes: Dictionary ch·ª©a c√°c DataFrame theo ERD

        Returns:
            True n·∫øu th√†nh c√¥ng, False n·∫øu th·∫•t b·∫°i
        """
        logger.info("üöÄ Starting Shopee full load data loading...")

        try:
            # Load theo th·ª© t·ª± ƒë·ªÉ tr√°nh foreign key constraint
            load_order = [
                "orders",  # Main table first
                "recipient_address",
                "order_items",
                "order_item_locations",
                "packages",
                "package_items",
                "invoice",
                "payment_info",
                "order_pending_terms",
                "order_warnings",
                "prescription_images",
                "buyer_proof_of_collection",
            ]

            success_count = 0
            total_count = len(load_order)

            for table_name in load_order:
                if table_name in dataframes:
                    df = dataframes[table_name]

                    if not df.empty:
                        # Truncate table tr∆∞·ªõc khi load (full load)
                        if self.truncate_table(table_name):
                            if self.load_dataframe_to_table(df, table_name, "append"):
                                success_count += 1
                                logger.info(
                                    f"‚úÖ Successfully loaded {table_name}: {len(df)} rows"
                                )
                            else:
                                logger.error(f"‚ùå Failed to load {table_name}")
                        else:
                            logger.error(f"‚ùå Failed to truncate {table_name}")
                    else:
                        logger.info(f"üì≠ Skipping empty {table_name}")
                        success_count += 1  # Empty table is considered success

            if success_count == total_count:
                logger.info(
                    f"üéâ Full load completed successfully: {success_count}/{total_count} tables"
                )
                return True
            else:
                logger.error(
                    f"‚ùå Full load failed: {success_count}/{total_count} tables"
                )
                return False

        except Exception as e:
            logger.error(f"‚ùå Full load failed with exception: {str(e)}")
            return False

    def load_orders_incremental(self, df: pd.DataFrame) -> bool:
        """
        Load d·ªØ li·ªáu incremental cho Shopee orders (UPSERT logic)

        Args:
            df: DataFrame ch·ª©a orders m·ªõi

        Returns:
            True n·∫øu th√†nh c√¥ng, False n·∫øu th·∫•t b·∫°i
        """
        logger.info("üîÑ Starting Shopee incremental data loading...")

        if df.empty:
            logger.info("üì≠ No incremental data to load")
            return True

        try:
            # Chu·∫©n h√≥a datetime ƒë·ªÉ tr√°nh l·ªói khi ghi DB
            df_export = self._convert_datetime_to_naive(df)

            target_full = self.table_mappings["orders"]
            schema, target_table = target_full.split(".")

            # 1) Ghi batch v√†o b·∫£ng t·∫°m trong c√πng schema (tr√°nh l·ªói ODBC b·∫±ng chunksize nh·ªè)
            temp_table = (
                f"temp_shopee_orders_{datetime.now().strftime('%Y%m%d_%H%M%S')}"
            )

            df_export.to_sql(
                name=temp_table,
                con=self.db_engine,
                schema=schema,
                if_exists="replace",
                index=False,
                method="multi",
                chunksize=15,
            )

            # 2) MERGE (UPSERT) theo kh√≥a order_sn, ch·ªâ UPDATE khi source.update_time m·ªõi h∆°n
            merge_sql = f"""
            MERGE [{schema}].[{target_table}] AS target
            USING [{schema}].[{temp_table}] AS source
              ON target.order_sn = source.order_sn

            WHEN MATCHED AND (
                 ISNULL(target.update_time, '1900-01-01') < ISNULL(source.update_time, '1900-01-01')
              OR ISNULL(target.order_status,'') <> ISNULL(source.order_status,'')
              OR ISNULL(target.shipping_carrier,'') <> ISNULL(source.shipping_carrier,'')
            ) THEN UPDATE SET
              target.region = source.region,
              target.currency = source.currency,
              target.cod = source.cod,
              target.total_amount = source.total_amount,
              target.order_status = source.order_status,
              target.shipping_carrier = source.shipping_carrier,
              target.payment_method = source.payment_method,
              target.estimated_shipping_fee = source.estimated_shipping_fee,
              target.message_to_seller = source.message_to_seller,
              target.create_time = source.create_time,
              target.update_time = source.update_time,
              target.days_to_ship = source.days_to_ship,
              target.ship_by_date = source.ship_by_date,
              target.buyer_user_id = source.buyer_user_id,
              target.buyer_username = source.buyer_username,
              target.actual_shipping_fee = source.actual_shipping_fee,
              target.actual_shipping_fee_confirmed = source.actual_shipping_fee_confirmed,
              target.goods_to_declare = source.goods_to_declare,
              target.note = source.note,
              target.note_update_time = source.note_update_time,
              target.pay_time = source.pay_time,
              target.dropshipper = source.dropshipper,
              target.dropshipper_phone = source.dropshipper_phone,
              target.split_up = source.split_up,
              target.buyer_cancel_reason = source.buyer_cancel_reason,
              target.cancel_by = source.cancel_by,
              target.cancel_reason = source.cancel_reason,
              target.buyer_cpf_id = source.buyer_cpf_id,
              target.fulfillment_flag = source.fulfillment_flag,
              target.pickup_done_time = source.pickup_done_time,
              target.reverse_shipping_fee = source.reverse_shipping_fee,
              target.order_chargeable_weight_gram = source.order_chargeable_weight_gram,
              target.prescription_check_status = source.prescription_check_status,
              target.pharmacist_name = source.pharmacist_name,
              target.prescription_approval_time = source.prescription_approval_time,
              target.prescription_rejection_time = source.prescription_rejection_time,
              target.edt_from = source.edt_from,
              target.edt_to = source.edt_to,
              target.booking_sn = source.booking_sn,
              target.advance_package = source.advance_package,
              target.return_request_due_date = source.return_request_due_date,
              target.is_buyer_shop_collection = source.is_buyer_shop_collection,
              target.etl_updated_at = GETUTCDATE()

            WHEN NOT MATCHED BY TARGET THEN
              INSERT (
                order_sn, region, currency, cod, total_amount, order_status, shipping_carrier,
                payment_method, estimated_shipping_fee, message_to_seller, create_time, update_time,
                days_to_ship, ship_by_date, buyer_user_id, buyer_username, actual_shipping_fee,
                actual_shipping_fee_confirmed, goods_to_declare, note, note_update_time, pay_time,
                dropshipper, dropshipper_phone, split_up, buyer_cancel_reason, cancel_by, cancel_reason,
                buyer_cpf_id, fulfillment_flag, pickup_done_time, reverse_shipping_fee,
                order_chargeable_weight_gram, prescription_check_status, pharmacist_name,
                prescription_approval_time, prescription_rejection_time, edt_from, edt_to, booking_sn,
                advance_package, return_request_due_date, is_buyer_shop_collection,
                etl_batch_id, etl_created_at, etl_updated_at, etl_source
              )
              VALUES (
                source.order_sn, source.region, source.currency, source.cod, source.total_amount,
                source.order_status, source.shipping_carrier, source.payment_method,
                source.estimated_shipping_fee, source.message_to_seller, source.create_time,
                source.update_time, source.days_to_ship, source.ship_by_date, source.buyer_user_id,
                source.buyer_username, source.actual_shipping_fee, source.actual_shipping_fee_confirmed,
                source.goods_to_declare, source.note, source.note_update_time, source.pay_time,
                source.dropshipper, source.dropshipper_phone, source.split_up, source.buyer_cancel_reason,
                source.cancel_by, source.cancel_reason, source.buyer_cpf_id, source.fulfillment_flag,
                source.pickup_done_time, source.reverse_shipping_fee, source.order_chargeable_weight_gram,
                source.prescription_check_status, source.pharmacist_name,
                source.prescription_approval_time, source.prescription_rejection_time,
                source.edt_from, source.edt_to, source.booking_sn, source.advance_package,
                source.return_request_due_date, source.is_buyer_shop_collection,
                source.etl_batch_id, source.etl_created_at, source.etl_updated_at, source.etl_source
              );
            """

            with self.db_engine.connect() as conn:
                conn.execute(text(merge_sql))
                # D·ªçn d·∫πp temp table
                conn.execute(text(f"DROP TABLE [{schema}].[{temp_table}]"))

            logger.info(
                f"‚úÖ Upserted {len(df_export)} incremental orders into {target_full} via MERGE"
            )
            return True

        except Exception as e:
            logger.error(f"‚ùå Incremental load failed: {str(e)}")
            return False

    def load_flat_orders_dataframe(
        self, df: pd.DataFrame, load_type: str = "full"
    ) -> bool:
        """
        Load DataFrame ph·∫≥ng v√†o b·∫£ng orders ch√≠nh (t∆∞∆°ng th√≠ch v·ªõi TikTok Shop pattern)

        Args:
            df: DataFrame ph·∫≥ng ch·ª©a orders
            load_type: 'full' ho·∫∑c 'incremental'

        Returns:
            True n·∫øu th√†nh c√¥ng, False n·∫øu th·∫•t b·∫°i
        """
        if df.empty:
            logger.info("üì≠ No data to load")
            return True

        try:
            # Convert datetime columns to timezone-naive
            df_export = self._convert_datetime_to_naive(df)

            table_full_name = self.table_mappings["orders"]

            if load_type == "full":
                # Truncate table tr∆∞·ªõc khi load
                if not self.truncate_table("orders"):
                    return False

                if_exists = "append"
            else:
                if_exists = "append"  # Incremental: append new data

            # Load to database (gi·ªõi h·∫°n chunksize nh·ªè ƒë·ªÉ tr√°nh qu√° t·∫£i tham s·ªë ODBC/SQL Server)
            df_export.to_sql(
                name=table_full_name.split(".")[1],
                con=self.db_engine,
                schema=table_full_name.split(".")[0],
                if_exists=if_exists,
                index=False,
                method="multi",
                chunksize=15,
            )

            logger.info(
                f"‚úÖ Loaded {len(df)} orders ({load_type} load) to {table_full_name}"
            )
            return True

        except Exception as e:
            logger.error(f"‚ùå Failed to load orders DataFrame: {str(e)}")
            return False

    def get_table_row_count(self, table_name: str) -> int:
        """
        L·∫•y s·ªë d√≤ng trong table

        Args:
            table_name: T√™n table

        Returns:
            S·ªë d√≤ng trong table
        """
        table_full_name = self.table_mappings.get(table_name)
        if not table_full_name:
            return 0

        try:
            with self.db_engine.connect() as conn:
                result = conn.execute(text(f"SELECT COUNT(*) FROM {table_full_name}"))
                count = result.scalar()
                return count
        except Exception as e:
            logger.error(f"‚ùå Failed to get row count for {table_full_name}: {str(e)}")
            return 0

    def validate_data_integrity(self) -> Dict[str, Any]:
        """
        Ki·ªÉm tra t√≠nh to√†n v·∫πn d·ªØ li·ªáu sau khi load

        Returns:
            Dictionary ch·ª©a k·∫øt qu·∫£ validation
        """
        logger.info("üîç Validating data integrity...")

        validation_results = {}

        for table_name, table_full_name in self.table_mappings.items():
            try:
                row_count = self.get_table_row_count(table_name)
                validation_results[table_name] = {
                    "row_count": row_count,
                    "status": "success" if row_count >= 0 else "error",
                }
            except Exception as e:
                validation_results[table_name] = {
                    "row_count": 0,
                    "status": "error",
                    "error": str(e),
                }

        # Log validation results
        for table_name, result in validation_results.items():
            if result["status"] == "success":
                logger.info(f"‚úÖ {table_name}: {result['row_count']} rows")
            else:
                logger.error(f"‚ùå {table_name}: {result.get('error', 'Unknown error')}")

        return validation_results
